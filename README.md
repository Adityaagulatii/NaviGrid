ğŸ—ºï¸ NaviGrid \
Camera-based indoor navigation â€” no beacons, no 3D mapping, just your phone.

ğŸ¬ Watch NaviGrid in action: \
[Demo](https://vimeo.com/1168262894?share=copy&fl=sv&fe=ci)

ğŸ“Œ Overview
- Eliminates the need for expensive indoor navigation infrastructure 
- No BLE beacons, no Wi-Fi triangulation systems, no 3D building scans 
- Users take a photo of a floorplan and annotate the rooms they want to navigate between 
- Uses Computer Vision and OCR to understand the layout 
- Determines current location, calculates an optimal route, and delivers turn-by-turn directions
- Navigating any new indoor space is as simple as snapping a photo

ğŸ’¡ Inspiration
- Indoor navigation has countless real-world applications â€” campus wayfinding, robotics, drone delivery, and accessibility for blind and visually impaired individuals
-Current solutions are long, complex, and expensive, typically requiring:
        Deployment of hardware like BLE beacons or Wi-Fi access points
        Full 3D models of the facility
        All because GPS simply doesn't work indoors
- Existing research inspired this project:
          Floorplan2Guide â€” uses LLMs to parse floorplans for blind and low-vision (BLV) navigation [link](https://arxiv.org/abs/2512.12177)
          Snap&Nav â€” a smartphone-based system that analyzes floor maps and detects intersections for indoor guidance [link](https://dl.acm.org/doi/10.1145/3676522)
- Both prior systems were still complex and resource-heavy
        NaviGrid's goal: strip indoor navigation down to its simplest form â€” no beacons, no 3D mapping, no expensive infrastructure, just your camera

\
âš™ï¸ How It Works \
ğŸ“¸ Step 1 â€” Capture
        Take a photo of the building's floorplan

âœï¸ Step 2 â€” Annotate
        Mark the rooms or points you want to navigate between

ğŸ§  Step 3 â€” Parse
        NaviGrid processes the floorplan using Computer Vision and OCR

ğŸ•¸ï¸ Step 4 â€” Build Graph
        A routing graph is constructed from annotated nodes and edges

ğŸ§­ Step 5 â€” Navigate
        Turn-by-turn directions guide you to your destination

\
ğŸ¯ Use Cases \
ğŸ“ Campus Navigation â€” Help new students find classrooms, offices, and facilities \
â™¿ Accessibility â€” Empower blind and visually impaired individuals to navigate independently \
ğŸ¤– Robotics â€” Provide autonomous systems with a lightweight indoor mapping solution \
ğŸš Drone Delivery â€” Enable path planning for indoor drone navigation systems

\
ğŸ—‚ï¸ Project Structure
NaviGrid \
â”œâ”€â”€ lower_level \
â”‚   â”œâ”€â”€ nodes.py                # Step 1: Load floorplan image + annotations â†’ extract nodes \
â”‚   â”œâ”€â”€ edges.py                # Step 2: Connect nodes by defining edges/paths \
â”‚   â””â”€â”€ navigate.py             # Step 3: Run navigation on lower level floor \
â”‚
â”œâ”€â”€ first_floor \
â”‚   â”œâ”€â”€ nodes.py                # Step 1: Load floorplan image + annotations â†’ extract nodes \
â”‚   â”œâ”€â”€ edges.py                # Step 2: Connect nodes by defining edges/paths \
â”‚   â””â”€â”€ navigate.py             # Step 3: Run navigation on first floor \
â”‚
â”œâ”€â”€ full_navigation.py          # Full multi-floor navigation pipeline \
â”œâ”€â”€ requirements.txt            # Python dependencies \
â””â”€â”€ README.md


